# Self-Improving Repo Builder v4

A multi-agent, text-to-code system that generates **complete, runnable software repositories** from natural language descriptions, then **verifies, repairs, and executes them automatically**.

**Version 4.0** - Now with interactive Streamlit UI, enhanced stability, and production-ready deployment options.

This project explores autonomous refinement loops using LLM agents, inspired by research in self-improving systems and agentic workflows.

---

## What This Project Does

Given a prompt like:

> "Build a FastAPI todo app with SQLite database and CRUD operations"

The system will:

1. **Plan** the full project structure
2. **Generate** every required file (code, configs, README, requirements)
3. **Modernize** code to use latest library APIs
4. **Verify** correctness (syntax, imports, runtime errors, common issues)
5. **Repair** errors automatically with retry loops
6. **Execute** the project in an isolated sandbox
7. **Return** a ready-to-run repository (ZIP or local folder)

No manual scaffolding. No partial code. No broken imports. No deprecated APIs.

---

## ğŸ†• What's New in v4

### **Major New Features:**

âœ… **Interactive Streamlit UI**

- Beautiful web interface for non-technical users
- Real-time progress tracking with visual feedback
- One-click example prompts to get started
- Live project preview and file listing
- Download management with project history
- Mobile-friendly responsive design
- Built-in usage guide and troubleshooting

âœ… **Three Deployment Modes**

- **Streamlit UI**: Interactive web interface (NEW!)
- **FastAPI**: REST API for programmatic access
- **CLI**: Command-line for automation and scripting

âœ… **Enhanced User Experience**

- Visual progress indicators during generation
- Success/failure statistics dashboard
- Project history tracking
- Quick-start example library
- Categorized prompt templates
- Detailed error reporting with expandable logs

### **Streamlit Features:**

- ğŸ¨ Modern gradient-styled interface
- ğŸ“Š Real-time statistics (total projects, success rate)
- ğŸ“œ Recent project history sidebar
- ğŸ”§ Configurable settings (model, iterations)
- ğŸ“¦ Categorized example prompts
- ğŸ“– Built-in user guide
- ğŸš€ One-click generation and download
- ğŸ’¾ Automatic session state management

---

## âš¡ Performance Optimizations

**v4.0 introduces significant efficiency improvements:**

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Input Tokens** | 3,900 | 2,300 | **41% â†“** |
| **Output Tokens** | 4,400 | 2,800 | **36% â†“** |
| **Total Tokens** | 8,300 | 5,100 | **38% â†“** |
| **Generation Speed** | 30-60s | 15-30s | **~50% faster** |
| **Cost per Project** | Higher | Lower | **~38% savings** |

**Key Optimization Techniques:**
- ğŸ”„ **Batch Processing**: Generate all files in a single LLM call instead of per-file generation
- ğŸ¯ **Smart Quick-Fixes**: Regex-based repairs for common issues (no LLM needed)
- ğŸ“ **Efficient Prompting**: Streamlined prompts that request exactly what's needed
- ğŸš€ **Groq Infrastructure**: Leveraging Groq's high-speed inference with Llama 3.3 70B
- ğŸ”§ **Reduced Agent Calls**: Consolidated modernization and repair operations

These optimizations mean faster generation times, lower costs, and more efficient resource usage while maintaining the same high-quality output.

---

## Key Capabilities

* **Multi-Agent Architecture**
  * **Planner**: Converts intent â†’ structured project plan with JSON validation & repair
  * **Generator**: Creates full file contents with latest API patterns
  * **Modernizer**: Updates deprecated code patterns to latest APIs
  * **Verifier**: Performs static + runtime validation (syntax, imports, error handling)
  * **Repair**: Fixes detected issues iteratively (auto-wraps JSON parsing, fixes dict access, etc.)
  * **Integrator**: Assembles a final runnable repo

* **Autonomous Refinement Loop**
  * Generation â†’ Modernization â†’ Verification â†’ Repair â†’ Re-verification
  * Continues until success or max iterations (default: 3)
  * Each iteration intelligently targets specific error types

* **Safe Execution Sandbox**
  * Isolated filesystem with Windows-safe cleanup
  * Dependency installation in temp environment
  * Timeout enforcement (configurable)
  * Structured execution results
  * Runtime error detection (JSON parsing, KeyError, etc.)

* **Robust Error Handling**
  * JSON parsing with automatic repair (3 retry attempts)
  * Dictionary access validation
  * API call error handling
  * File operation safety checks
  * Async/await validation

* **Multiple Interfaces**
  * **Streamlit UI**: Beautiful web interface for all users
  * **FastAPI**: REST API for integration and automation
  * **CLI**: Command-line for scripts and power users
  * Interactive API documentation (FastAPI)
  * Comprehensive error messages

* **100% Open Source Stack**
  * Python 3.10+, FastAPI, LangChain, LangGraph, Streamlit
  * Groq's Llama 3.3 70B Versatile for blazing-fast generation
  * Pydantic v2 for type safety
  * Comprehensive error handling

* **Optimized Performance**
  * **41% reduction in input tokens** (3.9k â†’ 2.3k)
  * **36% reduction in output tokens** (4.4k â†’ 2.8k)
  * Batch processing for multiple files
  * Smart quick-fix patterns to minimize LLM calls
  * Efficient prompt engineering

---

## High-Level Architecture

```
User Input (Streamlit/API/CLI)
   â†“
PlannerAgent â†’ ProjectSpec (with JSON validation & repair)
   â†“
GeneratorAgent (creates all files)
   â†“
ModernizerAgent (updates to latest API patterns)
   â†“
VerifierAgent (syntax + runtime + common issues)
   â†“
RepairAgent (if needed, auto-fixes common patterns)
   â†“ (loop up to 3x)
Integrator â†’ ZIP file
   â†“
Return to User (Download/Response)
```

This separation keeps reasoning, generation, validation, and execution strictly decoupled.

---

## Repository Structure

```

self_evolving_repo_builder/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ planner.py        # Intent â†’ ProjectSpec with robust JSON parsing
â”‚   â”œâ”€â”€ generator.py      # File generation with modern patterns
â”‚   â”œâ”€â”€ verifier.py       # Static + runtime validation
â”‚   â”œâ”€â”€ repair.py         # Targeted fixes with auto-patterns
â”‚   â”œâ”€â”€ modernizer.py     # Updates deprecated code to latest APIs
â”‚   â””â”€â”€ integrator.py     # Final assembly into ZIP
â”œâ”€â”€ graph/
â”‚   â””â”€â”€ build_graph.py    # LangGraph workflow orchestration
â”œâ”€â”€ execution/
â”‚   â”œâ”€â”€ sandbox.py        # Isolated execution (Windows-safe)
â”‚   â””â”€â”€ runner.py         # Project lifecycle runner
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ project_spec.py   # Strongly-typed contracts (Pydantic v2)
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ planner.txt       # Enhanced with JSON validation rules
â”‚   â”œâ”€â”€ generator.txt     # Modern API patterns
â”‚   â”œâ”€â”€ verifier.txt      # Code quality analysis
â”‚   â””â”€â”€ repair.txt        # Error fixing with defensive patterns
â”œâ”€â”€ api/
â”‚   â””â”€â”€ server.py         # FastAPI endpoint (direct ZIP response)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ fs.py             # Filesystem helpers
â”‚   â””â”€â”€ json_validator.py # Robust JSON parsing & repair
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ test_config.py    # Test scenarios and validation rules
â”‚   â””â”€â”€ windows_config.py # Windows-specific file handling
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml       # Streamlit UI configuration (theme, server, telemetry)
â”œâ”€â”€ streamlit_app.py      # Interactive Streamlit UI
â”œâ”€â”€ main.py               # CLI entrypoint with progress tracking
â”œâ”€â”€ requirements.txt      # All dependencies
â”œâ”€â”€ .env.example          # Environment template
â””â”€â”€ README.md             # This file
```

---

## Installation

### 1. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure environment variables

```bash
cp .env.example .env
```

Edit `.env` and add:

```env
GROQ_API_KEY=your_groq_api_key_here

# Optional: LangSmith tracing
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=your_langsmith_key_here
```

Get your Groq API key from: https://console.groq.com/keys

---

## Usage

### ğŸ¨ Streamlit UI Mode (NEW - Recommended for Most Users)

The easiest way to use the AI Code Generator with a beautiful web interface.

#### **Start the Streamlit app:**

```bash
streamlit run streamlit_app.py
```

The app will open automatically in your browser at **http://localhost:8501**

#### **Features:**

- **ğŸš€ Generate Tab**: Main interface for project generation
  - Text area for project description
  - Real-time progress tracking
  - Visual status updates
  - Quick tips sidebar
  - Download button with file preview
  - Next steps guide

- **ğŸ“¦ Examples Tab**: One-click example prompts
  - Web API examples (FastAPI, authentication, blogs)
  - AI/ML examples (chatbots, RAG pipelines)
  - Data tools (scrapers, analyzers)
  - CLI utilities and automation
  - Categorized by project type

- **ğŸ“– Guide Tab**: Built-in documentation
  - How the multi-agent workflow works
  - Tips for writing effective prompts
  - Troubleshooting common issues
  - Configuration explanations

- **âš™ï¸ Settings Sidebar**:
  - Model selection (Groq's Llama 3.3 70B)
  - Max repair iterations (1-5)
  - Real-time statistics
  - Project history
  - About section

#### **Example Workflow:**

1. Open Streamlit app
2. Click an example or type your own description
3. Click "ğŸš€ Generate Project"
4. Watch real-time progress
5. Download your ZIP file
6. Follow the "Next Steps" guide

#### **Streamlit Screenshots:**

The UI features:

- Modern gradient headers
- Color-coded status boxes (success/error/info)
- Progress bars with gradient styling
- Responsive three-column layout
- Mobile-friendly design
- Dark mode support (via Streamlit theme)

---

### ğŸ’» CLI Mode (For Automation & Scripting)

```bash
# Interactive mode with progress tracking
python main.py

# One-shot prompt
python main.py "build a FastAPI todo app"

# Custom output directory
python main.py "create a web scraper" --output ./my_projects
```

**Example Output:**
```
ğŸ¤– Text-to-Code Generator
==================================================

ğŸ“ Processing: build a FastAPI todo app
==================================================

âš™ï¸  Initializing workflow...
ğŸ“‹ Planning project structure...
ğŸ”¨ Generating code files...
ğŸ”„ Modernizing code to latest patterns...
   ğŸ” Running syntax checks...
   ğŸ” Running runtime tests...
   ğŸ” Checking for common issues...
âœ… Verifying code quality...
ğŸ“¦ Packaging project...

âœ… Success! Project generated:
ğŸ“¦ ./output/fastapi_todo_app_20260119_143022.zip

ğŸ“Š Summary:
   - Files: 8
   - Iterations: 1
```

---

### ğŸ”Œ API Mode (For Integration & Programmatic Access)

#### **Start the server:**

```bash
uvicorn api.server:app --reload --host 0.0.0.0 --port 8000
```

#### **Generate a project:**

**Using cURL:**

```bash
curl -X POST http://localhost:8000/generate \
  -H "Content-Type: application/json" \
  -d '{"query": "build a todo app with FastAPI"}' \
  --output project.zip
```

**Using Python:**

```python
import requests

response = requests.post(
    "http://localhost:8000/generate",
    json={"query": "create a web scraper"},
    timeout=300  # 5 minute timeout
)

with open("project.zip", "wb") as f:
    f.write(response.content)

print("âœ… Downloaded project.zip")
```

**Using JavaScript:**

```javascript
const response = await fetch('http://localhost:8000/generate', {
  method: 'POST',
  headers: {'Content-Type': 'application/json'},
  body: JSON.stringify({query: 'create a calculator'})
});

const blob = await response.blob();
// Save or download blob
```

#### **Interactive API Docs:**

Visit **http://localhost:8000/docs** for:

- Interactive API testing
- Request/response examples
- Direct file downloads
- Full endpoint documentation

---

## Example Prompts

### Web APIs

* "Create a FastAPI todo application with SQLite database, CRUD operations, and Pydantic models"
* "Build a RESTful blog API with FastAPI, SQLAlchemy ORM, and PostgreSQL support"
* "Create a FastAPI authentication system with JWT tokens, user registration, and login"

### AI/ML

* "Build an essay writing workflow using LangGraph"
* "Build a chatbot using LangChain with conversation memory and streaming responses"
* "Generate a RAG pipeline with PDF parsing and vector search"

### Data Tools

* "Build a web scraper using BeautifulSoup that extracts product data and saves to CSV"
* "Create a data analysis tool with pandas and matplotlib that reads CSV and generates visualizations"

### CLI & Automation

* "Create a simple command-line number guessing game with score tracking"
* "Build an email automation script with template support and attachment handling"
* "Create a todo list CLI app with SQLite backend"

### Other

* "Build a Discord bot with slash commands"
* "Create a simple calculator script with add, subtract, multiply, divide"

---

## Advanced Features

### Automatic Code Modernization

The system automatically updates deprecated patterns:

```python
# Old (deprecated)
from langchain.llms import OpenAI
chain = LLMChain(llm=llm, prompt=prompt)
result = chain.run(input)

# New (automatically modernized)
from langchain_openai import OpenAI
chain = prompt | llm
result = chain.invoke(input)
```

### Runtime Error Prevention

Automatically adds defensive programming patterns:

```python
# Before
data = json.loads(response)
value = data['key']

# After (auto-generated)
try:
    data = json.loads(response)
except json.JSONDecodeError as e:
    print(f"JSON error: {e}")
    data = {}

value = data.get('key', 'default')
```

### Smart Verification

Checks for:

- âœ… Syntax errors (AST parsing)
- âœ… Import errors (compile testing)
- âœ… Runtime errors (JSON, KeyError, TypeErrors)
- âœ… Missing error handling patterns
- âœ… Async/await mismatches
- âœ… File operation safety
- âœ… API call error handling
- âœ… Dictionary access validation

---

## Why This Project Matters

This is **not** a template generator.

It demonstrates:

* **Agent-based decomposition** of complex software tasks
* **Automated verification and repair loops** with targeted fixes
* **Programmatic reasoning** about code correctness
* **Runtime error prevention** through static analysis
* **Practical application** of LangGraph beyond demos
* **Self-improving systems** that learn from failures
* **User-friendly interfaces** for both technical and non-technical users
* **Foundations** for autonomous developer tools

This architecture can be extended into:

* Internal developer platforms
* Auto-scaffolding tools for microservices
* AI coding copilots with verification
* Research on autonomous software agents
* Educational tools for learning software patterns
* Code review automation
* CI/CD integration for scaffolding
* Low-code/no-code platforms

---

## Troubleshooting

### Streamlit Issues

**App won't start:**
```
Error: No module named 'streamlit'
```
**Solution**: Install dependencies: `pip install -r requirements.txt`

**Blank screen or loading forever:**
**Solution**: 

- Check browser console for errors
- Try a different browser
- Clear browser cache
- Restart the Streamlit app

**Example buttons not working:**
**Solution**: This is expected - buttons populate the text area. Type in the text area and click Generate.

### API Key Errors
```
Error: GROQ_API_KEY not found
```
**Solution**: Ensure `.env` exists and contains a valid `GROQ_API_KEY`

Get your API key from https://console.groq.com/keys

### JSON Parsing Errors
```
Error: Failed to parse planner response
```
**Solution**: The system has 3-retry logic with automatic repair. If this persists:
- Check Groq API status
- Try a simpler prompt first
- Review console output for detailed errors

### Windows File Locking

```
Error: [WinError 32] The process cannot access the file
```
**Solution**: The system includes Windows-safe cleanup with retry logic. If issues persist:

- Close any file explorers viewing temp directories
- Check no processes are holding file locks
- Restart the application

### Generation Timeouts

```
Error: Generation timeout
```

**Solution**:

- Increase timeout in settings (Streamlit) or client (API)
- Simplify the prompt
- Check Groq API rate limits and quotas
- Try during off-peak hours

### Download Issues (Streamlit)

**Download button doesn't appear:**
**Solution**:

- Ensure generation completed successfully
- Check for error messages
- Look at the Recent Projects sidebar
- Try regenerating

**ZIP file is empty or corrupted:**
**Solution**:

- Check error logs in console
- Try a different browser
- Ensure sufficient disk space
- Verify file permissions

---

## Configuration

### Streamlit Settings

In the app sidebar, you can configure:

- **Model**: Groq's Llama 3.3 70B Versatile (optimized for code generation)
- **Max Iterations**: 1-5 repair attempts (default: 3)

### Adjust Max Iterations (Code)

In `schemas/project_spec.py`:

```python
class AgentState(BaseModel):
    # ...
    max_iterations: int = 3  # Change to 5 for more repair attempts
```

### Adjust Timeout

In `execution/sandbox.py`:

```python
class SandboxRunner:
    def __init__(self, timeout: int = 30):  # Change to 60 for longer tests
```

### Change Model

In `graph/build_graph.py`:

```python
llm = ChatGroq(
    model="llama-3.3-70b-versatile",  # Fast and capable model from Groq
    temperature=0.1
)
```

### Customize Streamlit UI

In `streamlit_app.py`, you can modify:

- Color schemes (CSS in markdown section)
- Page layout (`layout="wide"`)
- Example prompts (examples list)
- Tab organization
- Sidebar content

---

## Deployment Options

### Local Development
```bash
# Streamlit
streamlit run streamlit_app.py

# FastAPI
uvicorn api.server:app --reload

# CLI
python main.py
```

### Production (Coming Soon)

#### Docker (Planned)
```bash
# Streamlit
docker build -t ai-code-gen-streamlit .
docker run -p 8501:8501 ai-code-gen-streamlit

# FastAPI
docker build -t ai-code-gen-api .
docker run -p 8000:8000 ai-code-gen-api
```

#### Cloud Deployment (Planned)
- AWS: EC2, ECS, or App Runner
- GCP: Cloud Run or App Engine
- Azure: Container Instances or App Service
- Streamlit Cloud (for Streamlit UI)

---

## Development & Contributing

### Project Philosophy

This project prioritizes:
1. **Correctness** over speed
2. **Explainability** over magic
3. **Composability** over monoliths
4. **Safety** over convenience
5. **User experience** over complexity

### Code Style

- Type hints everywhere (Python 3.10+ native types)
- Docstrings for all public functions
- Error handling at boundaries
- Comprehensive logging for debugging
- Component-based UI design (Streamlit)

### Testing

```bash
# CLI test
python main.py "create a hello world script"

# API test
python test_simple_api.py

# Streamlit test (manual)
streamlit run streamlit_app.py
# Then test the UI manually

# Manual extraction test
unzip output/*.zip -d test_output
cd test_output
cat README.md
python main.py
```

---

## Performance Benchmarks

| Query Complexity | Avg. Time | Success Rate |
|-----------------|-----------|--------------|
| Simple (hello world) | 15-30s | 95% |
| Medium (todo app) | 45-90s | 85% |
| Complex (full API) | 1.5-3 min | 75% |

*Based on Groq's Llama 3.3 70B with 3 repair iterations*

**Optimization Results:**
- **Input Tokens**: 3.9k â†’ 2.3k (41% reduction)
- **Output Tokens**: 4.4k â†’ 2.8k (36% reduction)
- **Total Token Savings**: ~38% overall
- **Cost Reduction**: Proportional to token savings
- **Speed Improvement**: Faster due to Groq's inference speed + fewer tokens

**Streamlit Performance:**
- Initial load: 2-3 seconds
- Generation: Same as CLI/API
- Download: Instant (client-side)
- UI responsiveness: <100ms

---

## References

* LangChain: [https://python.langchain.com](https://python.langchain.com)
* LangGraph: [https://langchain-ai.github.io/langgraph](https://langchain-ai.github.io/langgraph)
* Groq API: [https://console.groq.com](https://console.groq.com)
* Pydantic: [https://docs.pydantic.dev](https://docs.pydantic.dev)
* FastAPI: [https://fastapi.tiangolo.com](https://fastapi.tiangolo.com)
* Streamlit: [https://streamlit.io](https://streamlit.io)

---

## Development Status & Roadmap

This project is under active development.
APIs, internal abstractions, and agent behavior may change.

**Current Focus:** User experience, deployment options, and production readiness.

### Recent Improvements (v4.0) âœ…

- âœ… **Migrated to Groq's Llama 3.3 70B** for faster inference
- âœ… **Performance Optimization** - 41% reduction in input tokens, 36% in output tokens
- âœ… **Batch Processing** - Generate all files in single LLM call
- âœ… Interactive Streamlit web UI with modern design
- âœ… Real-time progress tracking and visual feedback
- âœ… Example prompt library with categories
- âœ… Built-in user guide and troubleshooting
- âœ… Project history and statistics dashboard
- âœ… Session state management for smooth UX
- âœ… Mobile-friendly responsive design
- âœ… One-click download with file preview

### v3.0 Features âœ…

- âœ… Simplified FastAPI endpoint (direct ZIP response)
- âœ… Robust JSON parsing with 3-retry logic
- âœ… Runtime error detection and prevention
- âœ… Windows-safe file operations with retry cleanup
- âœ… Automatic error pattern fixes
- âœ… Enhanced verification with common issue detection

### Planned Improvements ğŸš§

- [ ] ğŸ¯ Advanced Features
  - [ ] Test generation for generated code
  - [ ] Incremental updates to existing projects
  - [ ] Template library for common patterns
  - [ ] LLM response caching for similar queries
  - [ ] Custom agent configuration UI

---

## Acknowledgments

Built with â¤ï¸ using:
- **LangChain & LangGraph** for agent orchestration
- **Groq's Llama 3.3 70B** for blazing-fast, high-quality code generation
- **Pydantic v2** for type safety
- **FastAPI** for the API layer
- **Streamlit** for the interactive UI

Special thanks to:
- The open-source community
- Early testers and contributors
- LangChain team for excellent documentation
- Streamlit team for the amazing framework
- Groq team for providing fast LLM inference

---

## Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests if applicable
4. Submit a pull request

### Areas for Contribution:
- UI/UX improvements for Streamlit
- Additional language support
- More comprehensive tests
- Docker and deployment configurations
- Documentation enhancements
- Bug fixes and stability improvements
- Example prompt library expansion
- Analytics and monitoring features

---

## Screenshots

### Streamlit UI

**Main Generation Interface:**
- Clean, modern design with gradient headers
- Three-panel layout: Generate, Examples, Guide
- Real-time progress tracking
- Success metrics and project history

**Example Library:**
- Categorized by project type
- One-click prompt insertion
- Quick-start templates

**Settings & Stats:**
- Model selection
- Iteration configuration
- Live success rate
- Recent project history

---

**â­ Star this repo if you find it useful!**

**ğŸ”§ Questions?** Open an issue or start a discussion.

**ğŸ› Found a bug?** Please report it with reproduction steps.

**ğŸ’¡ Feature request?** We'd love to hear your ideas!